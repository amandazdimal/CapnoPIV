{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d072bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate vorticity and divergence for 1 frame, and apply appropriate threshold for data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from metpy.units import units\n",
    "import metpy.calc as mpcalc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the data for the specified frame without headers\n",
    "uwind = pd.read_excel('Example_Velocity_Map_X.xlsx', header=None)\n",
    "vwind = pd.read_excel('Example_Velocity_Map_Y.xlsx', header=None)\n",
    "\n",
    "# Convert velocity data to units\n",
    "u = uwind.values * 5.86 * units('micrometer/min') #pull up data in units of distance/time\n",
    "v = vwind.values * 5.86 * units('micrometer/min') #our conversion = (pixels/frame)(36000um/1228pixels)(1frame/5min) = 5.86\n",
    "\n",
    "# Normalize the velocity\n",
    "normV = np.sqrt(u**2 + v**2)\n",
    "\n",
    "# Handle units manually during normalization\n",
    "un = u / normV\n",
    "vn = v / normV\n",
    "\n",
    "# Define grid spacing (assuming a regular grid)\n",
    "dx = 1 * units('micrometer')  # Replace with actual grid spacing\n",
    "dy = 1 * units('micrometer')  # Replace with actual grid spacing\n",
    "\n",
    "# Calculate vorticity & divergence\n",
    "vorticity = mpcalc.vorticity(u, v, dx=dx, dy=dy)\n",
    "divergence = mpcalc.divergence(u, v, dx=dx, dy=dy)\n",
    "\n",
    "# Calculate normalized vorticity & divergence\n",
    "vorticity_norm = normV * mpcalc.vorticity(un * normV.units, vn * normV.units, dx=dx, dy=dy)\n",
    "divergence_norm = normV * mpcalc.divergence(un * normV.units, vn * normV.units, dx=dx, dy=dy)\n",
    "\n",
    "# Apply threshold and set values within threshold range to NaN\n",
    "threshold_low, threshold_high = min, max\n",
    "vorticity_norm_magnitude = vorticity_norm.magnitude\n",
    "divergence_norm_magnitude = divergence_norm.magnitude\n",
    "\n",
    "vorticity_norm_magnitude[(vorticity_norm_magnitude > threshold_low) & (vorticity_norm_magnitude < threshold_high)] = np.nan\n",
    "divergence_norm_magnitude[(divergence_norm_magnitude > threshold_low) & (divergence_norm_magnitude < threshold_high)] = np.nan\n",
    "\n",
    "# Create mesh grid for plotting (assuming your data has shape [ny, nx])\n",
    "ny, nx = u.shape\n",
    "x = np.linspace(0, (nx-1)*dx.magnitude, nx)\n",
    "y = np.linspace(0, (ny-1)*dy.magnitude, ny)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Plot normalized vorticity\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "vmin, vmax = min, max  # Set the desired min and max values\n",
    "im = ax.contourf(X, Y, vorticity_norm_magnitude, cmap='RdBu_r', levels=np.linspace(vmin, vmax, 21))\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Normalized Vorticity')\n",
    "ax.set_title('Normalized Vorticity Frame 60\\nPositive: Counterclockwise, Negative: Clockwise')\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized divergence\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "vmin, vmax = min, max  # Set the desired min and max values\n",
    "im = ax.contourf(X, Y, divergence_norm_magnitude, cmap='RdBu_r', levels=np.linspace(vmin, vmax, 21))\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Normalized Divergence')\n",
    "ax.set_title('Normalized Divergence Frame 60\\nPositive: Diverging, Negative: Converging')\n",
    "plt.show()\n",
    "\n",
    "# Save normalized vorticity and divergence to Excel files\n",
    "vorticity_norm_df = pd.DataFrame(vorticity_norm_magnitude)\n",
    "divergence_norm_df = pd.DataFrame(divergence_norm_magnitude)\n",
    "\n",
    "vorticity_norm_df.to_excel('norm_vorticity_thresh.xlsx', index=False, header=False)\n",
    "divergence_norm_df.to_excel('norm_divergence_thresh.xlsx', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2111c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine min and max values of vorticity and divergence datasets for above cell vmin and vmax \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from metpy.units import units\n",
    "import metpy.calc as mpcalc\n",
    "\n",
    "def read_velocity_data(frame_number):\n",
    "    \"\"\"Read the velocity data for a given frame number.\"\"\"\n",
    "    uwind = pd.read_excel(f'Velocity_Map_X_213_Frame_{frame_number}.xlsx', header=None)\n",
    "    vwind = pd.read_excel(f'Velocity_Map_Y_213_Frame_{frame_number}.xlsx', header=None)\n",
    "    \n",
    "    # Convert velocity data to units\n",
    "    u = uwind.values * 5.86 * units('micrometer/min')\n",
    "    v = vwind.values * 5.86 * units('micrometer/min')\n",
    "    \n",
    "    return u, v\n",
    "\n",
    "def compute_vorticity_and_divergence(u, v, dx, dy):\n",
    "    \"\"\"Compute the vorticity and divergence from u and v components.\"\"\"\n",
    "    vorticity = mpcalc.vorticity(u, v, dx=dx, dy=dy)\n",
    "    divergence = mpcalc.divergence(u, v, dx=dx, dy=dy)\n",
    "    return vorticity, divergence\n",
    "\n",
    "def find_min_max_vorticity_and_divergence(frames):\n",
    "    min_vorticity = np.inf * units('1/s')\n",
    "    max_vorticity = -np.inf * units('1/s')\n",
    "    min_divergence = np.inf * units('1/s')\n",
    "    max_divergence = -np.inf * units('1/s')\n",
    "    \n",
    "    # Define grid spacing (assuming a regular grid)\n",
    "    dx = 1 * units('micrometer')  # Replace with actual grid spacing if known\n",
    "    dy = 1 * units('micrometer')  # Replace with actual grid spacing if known\n",
    "    \n",
    "    for frame in frames:\n",
    "        u, v = read_velocity_data(frame)\n",
    "        vorticity, divergence = compute_vorticity_and_divergence(u, v, dx, dy)\n",
    "        \n",
    "        min_vorticity_frame = np.min(vorticity)\n",
    "        max_vorticity_frame = np.max(vorticity)\n",
    "        min_divergence_frame = np.min(divergence)\n",
    "        max_divergence_frame = np.max(divergence)\n",
    "        \n",
    "        min_vorticity = min(min_vorticity, min_vorticity_frame)\n",
    "        max_vorticity = max(max_vorticity, max_vorticity_frame)\n",
    "        min_divergence = min(min_divergence, min_divergence_frame)\n",
    "        max_divergence = max(max_divergence, max_divergence_frame)\n",
    "        \n",
    "        print(f\"Frame {frame}: Min Vorticity = {min_vorticity_frame:.4f}, Max Vorticity = {max_vorticity_frame:.4f}\")\n",
    "        print(f\"Frame {frame}: Min Divergence = {min_divergence_frame:.4f}, Max Divergence = {max_divergence_frame:.4f}\")\n",
    "    \n",
    "    return min_vorticity, max_vorticity, min_divergence, max_divergence\n",
    "\n",
    "# Specify the frames to analyze\n",
    "frames = [frame numbers]\n",
    "\n",
    "# Find the minimum and maximum vorticity and divergence values\n",
    "min_vorticity, max_vorticity, min_divergence, max_divergence = find_min_max_vorticity_and_divergence(frames)\n",
    "print(f\"Overall Min Vorticity: {min_vorticity:.4f}\")\n",
    "print(f\"Overall Max Vorticity: {max_vorticity:.4f}\")\n",
    "print(f\"Overall Min Divergence: {min_divergence:.4f}\")\n",
    "print(f\"Overall Max Divergence: {max_divergence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae1c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upsampling files to match size of selected velocity regions\n",
    "\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Function to upsample a dataframe\n",
    "def upsample_dataframe(filename, new_shape, output_filename):\n",
    "    # Read the data\n",
    "    data = pd.read_excel(filename, header=None).values\n",
    "    \n",
    "    # Upsample the data\n",
    "    upsampled_data = resize(data, new_shape, mode='reflect', anti_aliasing=True)\n",
    "    \n",
    "    # Convert back to dataframe\n",
    "    df_upsampled = pd.DataFrame(upsampled_data)\n",
    "    \n",
    "    # Save the upsampled dataframe to an Excel file\n",
    "    df_upsampled.to_excel(output_filename, header=False, index=False)\n",
    "    \n",
    "    # Return the shape of the upsampled data\n",
    "    return df_upsampled.shape\n",
    "\n",
    "# Define the new shape\n",
    "new_shape = (920, 1228)\n",
    "\n",
    "# Upsample vorticity data\n",
    "vorticity_file = 'norm_vorticity_thresh.xlsx'\n",
    "upsampled_vorticity_file = 'upsampled_norm_vort_thresh.xlsx'\n",
    "vorticity_shape = upsample_dataframe(vorticity_file, new_shape, upsampled_vorticity_file)\n",
    "\n",
    "# Upsample divergence data\n",
    "divergence_file = 'norm_divergence_thresh.xlsx'\n",
    "upsampled_divergence_file = 'upsampled_norm_div_thresh.xlsx'\n",
    "divergence_shape = upsample_dataframe(divergence_file, new_shape, upsampled_divergence_file)\n",
    "\n",
    "# Print the shapes of the upsampled files\n",
    "print(f\"Shape of '{upsampled_vorticity_file}': {vorticity_shape[0]} rows x {vorticity_shape[1]} columns\")\n",
    "print(f\"Shape of '{upsampled_divergence_file}': {divergence_shape[0]} rows x {divergence_shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf432b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use mask to plot vorticity and divergence within selected regions only, and generate frequency distribution and CDF plots\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import cumfreq\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Function to apply mask and plot\n",
    "def apply_mask_and_plot(data_filename, mask_filename, output_filename, vmin, vmax, title, threshold_low, threshold_high, save_thresholded_filename=None):\n",
    "    # Read the data\n",
    "    data = pd.read_excel(data_filename, header=None).values\n",
    "    mask = pd.read_excel(mask_filename, header=None).values\n",
    "\n",
    "    # Check if data is loaded correctly\n",
    "    if data.size == 0:\n",
    "        print(f\"No data loaded from {data_filename}\")\n",
    "        return\n",
    "    if mask.size == 0:\n",
    "        print(f\"No mask loaded from {mask_filename}\")\n",
    "        return\n",
    "\n",
    "    # Resize mask to match the shape of the data\n",
    "    mask_resized = resize(mask, data.shape, mode='reflect', anti_aliasing=True)\n",
    "    mask_resized = np.where(mask_resized > 0.5, 1, np.nan)  # Convert to binary mask with NaNs\n",
    "\n",
    "    # Apply the mask\n",
    "    masked_data = np.where(np.isnan(mask_resized), np.nan, data)\n",
    "\n",
    "    # Convert to DataFrame for easy plotting\n",
    "    masked_df = pd.DataFrame(masked_data)\n",
    "\n",
    "    # Plot heatmap of masked data\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(masked_df, annot=False, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    # Flatten the masked data and remove NaNs for plotting\n",
    "    flattened_data = masked_data.flatten()\n",
    "    flattened_data = flattened_data[~np.isnan(flattened_data)]\n",
    "\n",
    "    # Apply threshold to remove values between threshold_low and threshold_high\n",
    "    filtered_data = flattened_data[~((flattened_data > threshold_low) & (flattened_data < threshold_high))]\n",
    "\n",
    "    # Check if filtered data is empty\n",
    "    if filtered_data.size == 0:\n",
    "        print(f\"No data available after thresholding for {title}\")\n",
    "        return\n",
    "\n",
    "    # Frequency distribution plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.histplot(filtered_data, bins=50, kde=False)\n",
    "    plt.title(f'Frequency Distribution of {title}')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    # CDF plot\n",
    "    res = cumfreq(filtered_data, numbins=50)\n",
    "    x = res.lowerlimit + np.linspace(0, res.binsize * res.cumcount.size, res.cumcount.size)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(x, res.cumcount / len(filtered_data))\n",
    "    plt.title(f'Cumulative Distribution Function (CDF) of {title}')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Save the masked data to a new Excel file\n",
    "    masked_df.to_excel(output_filename, header=False, index=False)\n",
    "\n",
    "    # Save the filtered (thresholded) data to a new Excel file if requested\n",
    "    if save_thresholded_filename:\n",
    "        filtered_df = pd.DataFrame(filtered_data, columns=['Values'])\n",
    "        filtered_df.to_excel(save_thresholded_filename, index=False)\n",
    "        print(f\"Thresholded data saved to {save_thresholded_filename}\")\n",
    "\n",
    "# Define the min and max values for the color scale\n",
    "vmin_vorticity, vmax_vorticity = -1, 1  # Adjust based on your data range\n",
    "vmin_divergence, vmax_divergence = -1.9, 1.9  # Adjust based on your data range\n",
    "\n",
    "# Apply mask and plot for vorticity with its threshold\n",
    "apply_mask_and_plot(\n",
    "    'upsampled_norm_vort_thresh.xlsx', \n",
    "    'speed_area_selection.xlsx', \n",
    "    'masked_norm_vort_thresh.xlsx', \n",
    "    vmin_vorticity, vmax_vorticity, \n",
    "    'Masked Normalized Vorticity', \n",
    "    min, max, #include threshold values if needed\n",
    "    'masked_norm_vort_thresh_combinedplot.xlsx'\n",
    ")\n",
    "\n",
    "# Apply mask and plot for divergence with its threshold\n",
    "apply_mask_and_plot(\n",
    "    'upsampled_norm_div_thresh.xlsx', \n",
    "    'speed_area_selection.xlsx', \n",
    "    'masked_norm_div_thresh.xlsx', \n",
    "    vmin_divergence, vmax_divergence, \n",
    "    'Masked Normalized Divergence', \n",
    "    min, max, #include threshold values if needed\n",
    "    'masked_norm_div_threshcombinedplot.xlsx'\n",
    ")\n",
    "\n",
    "# Function to check the size of the Excel files (number of cells)\n",
    "def check_size(filename):\n",
    "    data = pd.read_excel(filename, header=None)\n",
    "    return data.shape\n",
    "\n",
    "# Check the sizes of the new files\n",
    "vort_size = check_size('masked_norm_vort_thresh.xlsx')\n",
    "div_size = check_size('masked_norm_div_thresh.xlsx')\n",
    "print(f\"Size of masked vorticity file: {vort_size}\")\n",
    "print(f\"Size of masked divergence file: {div_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency distribution vorticity for selected regions only, all time points\n",
    "\n",
    "# Load files to plot\n",
    "file_names = ['masked_norm_vort_thresh_combinedplot_1.xlsx',\n",
    "              'masked_norm_vort_thresh_combinedplot2.xlsx',\n",
    "              'masked_norm_vort_thresh_combinedplot3.xlsx',\n",
    "              'masked_norm_vort_thresh_combinedplot4.xlsx']\n",
    "\n",
    "# Assign the corresponding times to your datasets\n",
    "times = [timepoint values]\n",
    "\n",
    "#optional: create data threshold to remove background if needed\n",
    "threshold = \n",
    "\n",
    "#create a figure and axis object\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "#loop through each file and plot histogram with outline\n",
    "for file_name in file_names:\n",
    "    #read data from Excel file\n",
    "    df = pd.read_excel(file_name)\n",
    "    \n",
    "    #flatten the DataFrame to a single column and apply threshold\n",
    "    all_values = df.values.flatten()\n",
    "    non_blank_values_vorticity = all_values[(~pd.isna(all_values)) & (all_values < threshold value) | (all_values > threshold value)]\n",
    "    \n",
    "    #plot histogram with outline and no fill\n",
    "    ax.hist(non_blank_values_vorticity, bins=50, alpha=0.8, histtype='step', linewidth=2.5, label=file_name)\n",
    "\n",
    "#set labels and title for plot\n",
    "ax.set_xlabel('Vorticity Magnitude')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Frequency Distribution of Vorticity')\n",
    "\n",
    "#set axes limits and show plot\n",
    "ax.set_xlim(min, max)\n",
    "ax.set_ylim(0, max)\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99994a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency distribution divergence for selected regions only, all time points\n",
    "\n",
    "# Load files to plot\n",
    "file_names = ['masked_norm_div_thresh_combinedplot1.xlsx',\n",
    "              'masked_norm_div_thresh_combinedplot2.xlsx',\n",
    "              'masked_norm_div_thresh_combinedplot3.xlsx',\n",
    "              'masked_norm_div_thresh_combinedplot4.xlsx']\n",
    "\n",
    "# Assign the corresponding times to your datasets\n",
    "times = [timepoint values]\n",
    "\n",
    "#optional: create data threshold to remove background if needed\n",
    "threshold = \n",
    "\n",
    "#create a figure and axis object\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "#loop through each file and plot histogram with outline\n",
    "for file_name in file_names:\n",
    "    #read data from Excel file\n",
    "    df = pd.read_excel(file_name)\n",
    "    \n",
    "    #flatten the DataFrame to a single column and apply threshold\n",
    "    all_values = df.values.flatten()\n",
    "    non_blank_values_vorticity = all_values[(~pd.isna(all_values)) & (all_values < threshold value) | (all_values > threshold value)]\n",
    "    \n",
    "    #plot histogram with outline and no fill\n",
    "    ax.hist(non_blank_values_vorticity, bins=50, alpha=0.8, histtype='step', linewidth=2.5, label=file_name)\n",
    "\n",
    "#set labels and title for plot\n",
    "ax.set_xlabel('Divergence Magnitude')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Frequency Distribution of Divergence')\n",
    "\n",
    "#set axes limits and show plot\n",
    "ax.set_xlim(min, max)\n",
    "ax.set_ylim(0, max)\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b45ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count clockwise and counterclockwise vorticity values from each timepoint outside thresholded range\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the threshold range if needed\n",
    "lower_threshold = \n",
    "upper_threshold = \n",
    "\n",
    "# Load files to process\n",
    "file_names = ['masked_norm_vort_thresh_combinedplot_1.xlsx',\n",
    "              'masked_norm_vort_thresh_combinedplot2.xlsx',\n",
    "              'masked_norm_vort_thresh_combinedplot3.xlsx',\n",
    "              'masked_norm_vort_thresh_combinedplot4.xlsx']\n",
    "\n",
    "# Assign the corresponding times to your datasets\n",
    "times = [timepoint values]\n",
    "\n",
    "# Initialize counters for overall counts\n",
    "total_positive_count = 0\n",
    "total_negative_count = 0\n",
    "\n",
    "# Function to count positive and negative values outside the threshold range\n",
    "def count_values_outside_threshold(df, lower_threshold, upper_threshold):\n",
    "    # Get all numerical values from the DataFrame\n",
    "    all_values = df.values.flatten()\n",
    "    \n",
    "    # Remove NaN values\n",
    "    non_nan_values = all_values[~np.isnan(all_values)]\n",
    "    \n",
    "    # Filter values outside the threshold range\n",
    "    outside_threshold = non_nan_values[(non_nan_values < lower_threshold) | (non_nan_values > upper_threshold)]\n",
    "    \n",
    "    # Count positive and negative values\n",
    "    positive_count = np.sum(outside_threshold > 0)\n",
    "    negative_count = np.sum(outside_threshold < 0)\n",
    "    \n",
    "    return positive_count, negative_count\n",
    "\n",
    "# Iterate over each file and accumulate the counts\n",
    "for file_name, time in zip(file_names, times):\n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(file_name)\n",
    "    \n",
    "    # Count the values outside the threshold range\n",
    "    positive_count, negative_count = count_values_outside_threshold(df, lower_threshold, upper_threshold)\n",
    "    \n",
    "    # Print the results for each frame\n",
    "    print(f\"Frame {time} hr:\")\n",
    "    print(f\"Total positive values outside threshold: {positive_count}\")\n",
    "    print(f\"Total negative values outside threshold: {negative_count}\\n\")\n",
    "    \n",
    "    # Accumulate the counts\n",
    "    total_positive_count += positive_count\n",
    "    total_negative_count += negative_count\n",
    "\n",
    "# Print the overall counts\n",
    "print(\"Overall counts for all frames:\")\n",
    "print(f\"Total positive values outside threshold: {total_positive_count}\")\n",
    "print(f\"Total negative values outside threshold: {total_negative_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count divergence and convergence values from each timepoint outside thresholded range\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the threshold range if needed\n",
    "lower_threshold = \n",
    "upper_threshold = \n",
    "\n",
    "# Load files to process\n",
    "file_names = ['masked_norm_div_thresh_combinedplot1.xlsx',\n",
    "              'masked_norm_div_thresh_combinedplot2.xlsx',\n",
    "              'masked_norm_div_thresh_combinedplot3.xlsx',\n",
    "              'masked_norm_div_thresh_combinedplot4.xlsx']\n",
    "\n",
    "# Assign the corresponding times to your datasets\n",
    "times = [timepoint values]\n",
    "\n",
    "# Initialize counters for overall counts\n",
    "total_positive_count = 0\n",
    "total_negative_count = 0\n",
    "\n",
    "# Function to count positive and negative values outside the threshold range\n",
    "def count_values_outside_threshold(df, lower_threshold, upper_threshold):\n",
    "    # Get all numerical values from the DataFrame\n",
    "    all_values = df.values.flatten()\n",
    "    \n",
    "    # Remove NaN values\n",
    "    non_nan_values = all_values[~np.isnan(all_values)]\n",
    "    \n",
    "    # Filter values outside the threshold range\n",
    "    outside_threshold = non_nan_values[(non_nan_values < lower_threshold) | (non_nan_values > upper_threshold)]\n",
    "    \n",
    "    # Count positive and negative values\n",
    "    positive_count = np.sum(outside_threshold > 0)\n",
    "    negative_count = np.sum(outside_threshold < 0)\n",
    "    \n",
    "    return positive_count, negative_count\n",
    "\n",
    "# Iterate over each file and accumulate the counts\n",
    "for file_name, time in zip(file_names, times):\n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(file_name)\n",
    "    \n",
    "    # Count the values outside the threshold range\n",
    "    positive_count, negative_count = count_values_outside_threshold(df, lower_threshold, upper_threshold)\n",
    "    \n",
    "    # Print the results for each frame\n",
    "    print(f\"Frame {time} hr:\")\n",
    "    print(f\"Total positive values outside threshold: {positive_count}\")\n",
    "    print(f\"Total negative values outside threshold: {negative_count}\\n\")\n",
    "    \n",
    "    # Accumulate the counts\n",
    "    total_positive_count += positive_count\n",
    "    total_negative_count += negative_count\n",
    "\n",
    "# Print the overall counts\n",
    "print(\"Overall counts for all frames:\")\n",
    "print(f\"Total positive values outside threshold: {total_positive_count}\")\n",
    "print(f\"Total negative values outside threshold: {total_negative_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
